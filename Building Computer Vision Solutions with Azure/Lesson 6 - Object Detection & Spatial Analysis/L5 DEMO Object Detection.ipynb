{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please install the required Python modules/SDKs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find conda environment: ai-azure-c1\r\n",
      "You can list all discoverable environments with `conda info --envs`.\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "! activate ai-azure-c1\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"/opt/conda/envs/ai-azure-c1/lib/python3.8/site-packages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure Custom Vision - Object Detection Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import utility functions and Python modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from urllib.parse import urlparse\n",
    "from io import BytesIO\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os, time, uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image_in_cell(img_url):\n",
    "    response = requests.get(img_url)\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.cognitiveservices.vision.customvision.training import CustomVisionTrainingClient\n",
    "from azure.cognitiveservices.vision.customvision.prediction import CustomVisionPredictionClient\n",
    "from azure.cognitiveservices.vision.customvision.training.models import ImageFileCreateBatch, ImageFileCreateEntry, Region\n",
    "from msrest.authentication import ApiKeyCredentials\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources:\n",
    "- Azure Custom Vision Endpoint\n",
    "- Training Reource ID and Key\n",
    "- Prediction Resource ID and Key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make sure you have the correct Training and Prediction Endpoints, Keys and Resource IDs separately"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Training Endpoint resource must be for both training and prediction for this demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_ENDPOINT = \"https://nayanacustomvision.cognitiveservices.azure.com/\"\n",
    "training_key = \"ce08598caf404621b37136119dccd921\"\n",
    "training_resource_id = '/subscriptions/bb272072-9c6d-4e28-b814-947814c3e6ef/resourceGroups/nayana-ai-msft-azure/providers/Microsoft.CognitiveServices/accounts/nayanacustomvision'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREDICTION_ENDPOINT = 'https://nayanacustomvision-prediction.cognitiveservices.azure.com/'\n",
    "prediction_key = \"6b7c1fe2bea0431a8a3b4259749591e6\"\n",
    "prediction_resource_id = \"/subscriptions/bb272072-9c6d-4e28-b814-947814c3e6ef/resourceGroups/nayana-ai-msft-azure/providers/Microsoft.CognitiveServices/accounts/nayanacustomvision-Prediction\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate and authenticate the training client with endpoint and key "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_credentials = ApiKeyCredentials(in_headers={\"Training-key\": training_key})\n",
    "trainer = CustomVisionTrainingClient(TRAINING_ENDPOINT, training_credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.4-preview'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.api_version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate and authenticate the prediction client with endpoint and key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_credentials = ApiKeyCredentials(in_headers={\"Prediction-key\": prediction_key})\n",
    "predictor = CustomVisionPredictionClient(PREDICTION_ENDPOINT, prediction_credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.1'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.api_version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Training Project First"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Object Detection Training project has been created. Please move on.\n"
     ]
    }
   ],
   "source": [
    "# Find the object detection domain\n",
    "obj_detection_domain = next(domain for domain in trainer.get_domains() if domain.type == \"ObjectDetection\" and domain.name == \"General\")\n",
    "\n",
    "# Create a new project\n",
    "print (\"Your Object Detection Training project has been created. Please move on.\")\n",
    "project_name = uuid.uuid4()\n",
    "project = trainer.create_project(project_name, domain_id=obj_detection_domain.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Project Details as collective information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'e520aaa3-5090-42dd-89c0-9a7ae5d5b743',\n",
       " 'name': '26eb3b48-6102-45e0-8c35-1d2528aa7773',\n",
       " 'description': '',\n",
       " 'settings': {'domain_id': 'da2e3a8a-40a5-4171-82f4-58522f70fbc1',\n",
       "  'classification_type': 'Multilabel',\n",
       "  'target_export_platforms': [],\n",
       "  'use_negative_set': True,\n",
       "  'image_processing_settings': {'augmentation_methods': {'rotation': True,\n",
       "    'scaling': True,\n",
       "    'translation': True,\n",
       "    'horizontal flip': True,\n",
       "    'equalize': True,\n",
       "    'solarize': True,\n",
       "    'padtosquare': True}}},\n",
       " 'created': '2022-06-20T11:09:08.553Z',\n",
       " 'last_modified': '2022-06-20T11:09:08.553Z',\n",
       " 'dr_mode_enabled': False,\n",
       " 'status': 'Succeeded'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project.as_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Succeeded'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project.status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Tags based on training requirements\n",
    "- We have 2 tags in the training process \n",
    "  - Bird\n",
    "  - Flower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "bird_tag = trainer.create_tag(project.id, \"Bird\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_tag = trainer.create_tag(project.id, \"Flower\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VERY IMPORTANT - PAUSE HERE\n",
    "# Now, please go to the Custom Vision portal, upload and label your training images\n",
    "## Please read the following instructions:\n",
    "\n",
    "- The training images used in this demo can be found here: https://github.com/udacity/cd0461-building-computer-vision-solutions-with-azure-exercises/tree/main/resources/bird-flower\n",
    "- Please download these images from the GitHub repo\n",
    "- Please visit the Custom Vision Portal (https://computervision.api) and upload all of these images manually. \n",
    "- After that, you can label the tag region for each object directly at the portal. \n",
    "- This way, you don't need to use any third-party website or service to generate tag regions in the form of bounding box coordinates. If you have training images with those coordinates, you can use the optional section below to upload your images with the tagged objects via code.\n",
    "- Once you have uploaded and labeled all the training images at the portal, you can come back to this notebook and start the training process. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ====================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You can skip this section (between dotted lines) if you are uploading and labeling images manually at the portal.\n",
    "\n",
    "## Optional: Uploading image with bounding box coordinates and tag via code\n",
    "\n",
    "\n",
    "\n",
    "* If you have added bounding boxes and tags to every object to your images, you can upload these images with the tag regions via code.\n",
    "\n",
    "* This is an alternative to uploading and labeling images directly at the Custom Vision portal. \n",
    "\n",
    "* Here is an example image from the URL: https://raw.githubusercontent.com/udacity/cd0461-building-computer-vision-solutions-with-azure-exercises/main/resources/image-01-boundingbox.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_url = 'https://raw.githubusercontent.com/udacity/cd0461-building-computer-vision-solutions-with-azure-exercises/main/resources/image-01-boundingbox.png'\n",
    "show_image_in_cell(img_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step #1: Create the bounding box coordinates for every tag on your images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Make sure to add your folder full path and correct folder name of where all training images are located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_image_path = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls $local_image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"image_01.jpg\" is the same image as the one shown above\n",
    "\n",
    "flower_image_regions = {\"image_01\": [ 0.314344746162928, 0.405046480743692, 0.506493506493506, 0.34705621956618 ]}\n",
    "bird_image_regions = {\"image_01\": [ 0.208677685950413, 0.265161575918548, 0.19185360094451, 0.581673306772908 ]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step #2: Upload image with tag regions to the Custom Vision portal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_images_with_regions = []\n",
    "\n",
    "for file_name in flower_image_regions.keys():\n",
    "    x,y,w,h = flower_image_regions[file_name]\n",
    "    regions = [ Region(tag_id=flower_tag.id, left=x,top=y,width=w,height=h) ]\n",
    "  \n",
    "    with open(os.path.join (local_image_path, file_name + \".jpg\"), mode=\"rb\") as image_contents:\n",
    "        tagged_images_with_regions.append(ImageFileCreateEntry(name=file_name, contents=image_contents.read(), regions=regions))\n",
    "\n",
    "for file_name in bird_image_regions.keys():\n",
    "    x,y,w,h = bird_image_regions[file_name]\n",
    "    regions = [ Region(tag_id=bird_tag.id, left=x,top=y,width=w,height=h) ]\n",
    "  \n",
    "    with open(os.path.join (local_image_path, file_name + \".jpg\"), mode=\"rb\") as image_contents:\n",
    "        tagged_images_with_regions.append(ImageFileCreateEntry(name=file_name, contents=image_contents.read(), regions=regions))\n",
    "\n",
    "        \n",
    "training_upload_result = trainer.create_images_from_files(project.id, ImageFileCreateBatch(images=tagged_images_with_regions))\n",
    "if not training_upload_result.is_batch_successful:\n",
    "    for image in training_upload_result.images:\n",
    "        print(\"Image status: \", image.status)\n",
    "    exit(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step #3: Validate the image upload at the Custom Vision portal to make sure image uploading is done correctly with the coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_upload_result.is_batch_successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the image with tag regions is uploaded successfully,\n",
    "# you should see the image on the Custom Vision portal \n",
    "# with the proper tags and bounding boxes.\n",
    "\n",
    "show_image_in_cell('https://raw.githubusercontent.com/udacity/cd0461-building-computer-vision-solutions-with-azure-exercises/main/resources/image-01-labeled-data-upload-verify.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is the end of the optional section.  \n",
    "### ====================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Once you have uploaded and labeled all the training images at the portal, you can start the training process with the code below.\n",
    "\n",
    "## Start Object Detection Training\n",
    "- We will be keep checking every 10 seconds the training progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration = trainer.train_project(project.id)\n",
    "while (iteration.status != \"Completed\"):\n",
    "    iteration = trainer.get_iteration(project.id, iteration.id)\n",
    "    print (\"Training status: \" + iteration.status)\n",
    "    print (\"Waiting 10 seconds...\")\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After training is complete, we will check model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration.as_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration_list = trainer.get_iterations(project.id)\n",
    "for iteration_item in iteration_list:\n",
    "    print(iteration_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_perf = trainer.get_iteration_performance(project.id, iteration_list[0].id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_perf.as_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publishing the Model to the Project Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting the Iteration Name, this will be used when Model training is completed\n",
    "publish_iteration_name = \"udacity-2-classes-object-detection-custom\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The iteration is now trained. Publish it to the project endpoint\n",
    "trainer.publish_iteration(project.id, iteration.id, publish_iteration_name, prediction_resource_id)\n",
    "print (\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing Prediction\n",
    "- Using the predictor object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_image_path = '/home/workspace'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls $local_image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_prediction(image_file_name):\n",
    "    with open(os.path.join (local_image_path,  image_file_name), \"rb\") as image_contents:\n",
    "        results = predictor.detect_image(project.id, publish_iteration_name, image_contents.read())\n",
    "        # Display the results.\n",
    "        for prediction in results.predictions:\n",
    "            print(\"\\t\" + prediction.tag_name +\n",
    "                  \": {0:.2f}%\".format(prediction.probability * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_name = \"ENTER LOCAL TEST IMAGE FILE NAME HERE\"\n",
    "# You can upload a test image and replace \"flower.jpg\" with the name of your own image\n",
    "\n",
    "file_name = \"flower.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perform_prediction(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Checking the Image\n",
    "with open(os.path.join (local_image_path, file_name), 'rb') as img_code:\n",
    "    img_view_ready = Image.open(img_code)\n",
    "    plt.figure()\n",
    "    plt.imshow(img_view_ready)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_name_2 = \"ENTER LOCAL TEST IMAGE FILE NAME HERE\"\n",
    "# You can upload a test image and replace \"bird.jpg\" with the name of your own image\n",
    "\n",
    "file_name_2 = \"bird.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perform_prediction(file_name_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Checking the Image\n",
    "with open(os.path.join (local_image_path, file_name_2), 'rb') as img_code:\n",
    "    img_view_ready = Image.open(img_code)\n",
    "    plt.figure()\n",
    "    plt.imshow(img_view_ready)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
