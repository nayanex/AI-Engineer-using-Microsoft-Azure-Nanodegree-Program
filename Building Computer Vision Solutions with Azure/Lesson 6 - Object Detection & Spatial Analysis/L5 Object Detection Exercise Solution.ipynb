{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please install the required Python modules/SDKs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! activate ai-azure-c1\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"/opt/conda/envs/ai-azure-c1/lib/python3.8/site-packages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure Custom Vision - Object Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import utility functions and Python modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from urllib.parse import urlparse\n",
    "from io import BytesIO\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os, time, uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image_in_cell(img_url):\n",
    "    response = requests.get(img_url)\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.cognitiveservices.vision.customvision.training import CustomVisionTrainingClient\n",
    "from azure.cognitiveservices.vision.customvision.prediction import CustomVisionPredictionClient\n",
    "from azure.cognitiveservices.vision.customvision.training.models import ImageFileCreateBatch, ImageFileCreateEntry, Region\n",
    "from msrest.authentication import ApiKeyCredentials\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources:\n",
    "- Azure Custom Vision Endpoint\n",
    "- Training Reource ID and Key\n",
    "- Prediction Resource ID and Key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make sure you have the correct Training and Prediction Endpoints, Keys and Resource IDs separately"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Training Endpoint resource must be for both training and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_ENDPOINT = \"ENTER TRAINING ENDPOINT HERE\"\n",
    "training_key = \"ENTER TRAINING RESOURCE KEY HERE\"\n",
    "training_resource_id = 'ENTER TRAINING RESOURCE ID HERE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREDICTION_ENDPOINT = 'ENTER PREDICTION RESOURCE KEY HERE'\n",
    "prediction_key = \"ENTER PREDICTION RESOURCE KEY HERE\"\n",
    "prediction_resource_id = \"ENTER PREDICTION RESOURCE ID HERE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate and authenticate the training client with endpoint and key "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_credentials = ApiKeyCredentials(in_headers={\"Training-key\": training_key})\n",
    "trainer = CustomVisionTrainingClient(TRAINING_ENDPOINT, training_credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.api_version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate and authenticate the prediction client with endpoint and key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_credentials = ApiKeyCredentials(in_headers={\"Prediction-key\": prediction_key})\n",
    "predictor = CustomVisionPredictionClient(PREDICTION_ENDPOINT, prediction_credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.api_version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Training Project First"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the object detection domain\n",
    "obj_detection_domain = next(domain for domain in trainer.get_domains() if domain.type == \"ObjectDetection\" and domain.name == \"General\")\n",
    "\n",
    "# Create a new project\n",
    "print (\"Your Object Detection Training project has been created. Please move on.\")\n",
    "project_name = uuid.uuid4()\n",
    "project = trainer.create_project(project_name, domain_id=obj_detection_domain.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Project Details as collective information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.as_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Tags based on training requirements\n",
    "  \n",
    "- In the demo, we used images and tags for Bird and Flower. For this exercise, you can use the \"bottle\" tag or any other class/type of your own images.\n",
    "- Please modify the code accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bird_tag = trainer.create_tag(project.id, \"Bird\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_tag = trainer.create_tag(project.id, \"Flower\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VERY IMPORTANT - PAUSE HERE\n",
    "# Now, please go to the Custom Vision portal, upload and label your training images\n",
    "## Please read the following instructions:\n",
    "\n",
    "- Please visit the Custom Vision Portal (https://computervision.api) and upload all your training images manually. \n",
    "- After that, you can label the tag region for each object directly at the portal. \n",
    "- This way, you don't need to use any third-party website or service to generate tag regions in the form of bounding box coordinates. If you have training images with those coordinates, you can use the optional section in the demo Jupyter Notebook to upload your images with the tagged objects via code.\n",
    "\n",
    "### Once you have uploaded and labeled all the training images at the portal, you can come back to this notebook and start the training process. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the Object Detection Training\n",
    "- We will keep checking every 10 seconds during the training progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration = trainer.train_project(project.id)\n",
    "while (iteration.status != \"Completed\"):\n",
    "    iteration = trainer.get_iteration(project.id, iteration.id)\n",
    "    print (\"Training status: \" + iteration.status)\n",
    "    print (\"Waiting 10 seconds...\")\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After training is complete, we will check model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration.as_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration_list = trainer.get_iterations(project.id)\n",
    "for iteration_item in iteration_list:\n",
    "    print(iteration_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_perf = trainer.get_iteration_performance(project.id, iteration_list[0].id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_perf.as_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publishing the Model to the Project Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting the Iteration Name, this will be used when Model training is completed\n",
    "publish_iteration_name = \"udacity-2-classes-object-detection-custom\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The iteration is now trained. Publish it to the project endpoint\n",
    "trainer.publish_iteration(project.id, iteration.id, publish_iteration_name, prediction_resource_id)\n",
    "print (\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing Prediction\n",
    "- Using the predictor object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_image_path = '/home/workspace'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls $local_image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_prediction(image_file_name):\n",
    "    with open(os.path.join (local_image_path,  image_file_name), \"rb\") as image_contents:\n",
    "        results = predictor.detect_image(project.id, publish_iteration_name, image_contents.read())\n",
    "        # Display the results.\n",
    "        for prediction in results.predictions:\n",
    "            print(\"\\t\" + prediction.tag_name +\n",
    "                  \": {0:.2f}%\".format(prediction.probability * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_name = \"ENTER LOCAL TEST IMAGE FILE NAME HERE\"\n",
    "# Please upload a test image and replace \"flower.jpg\" with the name of your own image\n",
    "\n",
    "file_name = \"flower.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perform_prediction(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Checking the Image\n",
    "with open(os.path.join (local_image_path, file_name), 'rb') as img_code:\n",
    "    img_view_ready = Image.open(img_code)\n",
    "    plt.figure()\n",
    "    plt.imshow(img_view_ready)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_name_2 = \"ENTER LOCAL TEST IMAGE FILE NAME HERE\"\n",
    "# Please upload another test image and replace \"bird.jpg\" with the name of your own image\n",
    "\n",
    "file_name_2 = \"bird.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perform_prediction(file_name_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Checking the Image\n",
    "with open(os.path.join (local_image_path, file_name_2), 'rb') as img_code:\n",
    "    img_view_ready = Image.open(img_code)\n",
    "    plt.figure()\n",
    "    plt.imshow(img_view_ready)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting Model \n",
    "Note: This code is exact same as the Image classification model export. You just need to have the proper project ID and iteration ID specific to any custom vision solution, and the respective model from the selected iteration will be exported to the target platform and flavor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "platform = \"TensorFlow\"\n",
    "flavor = \"TensorFlowLite\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the export_iteration method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_process = trainer.export_iteration(project.id, iteration.id, platform, flavor, raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(export_process.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(export_process.output.status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code snippet is from Azure SDK and Documentation\n",
    "### https://docs.microsoft.com/en-us/azure/cognitive-services/custom-vision-service/export-programmatically\n",
    "### This step may take long time \n",
    "while (export_process.output.status == \"Exporting\"):\n",
    "    print (\"Waiting 10 seconds...\")\n",
    "    time.sleep(10)\n",
    "    exports = trainer.get_exports(project_id, selected_iteration_id)\n",
    "    for e in exports:\n",
    "        if e.platform == export_process.output.platform and e.flavor == export_process.output.flavor:\n",
    "            export = e\n",
    "            break\n",
    "    print(\"Export status is: \", export_process.output.status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(export_process.output.status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(export_process.output.download_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can choose any preferred name of the file download as exported model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Downloading the model from url\n",
    "if export_process.output.status == \"Done\":\n",
    "    # Ready to Download\n",
    "    model_export_file = requests.get(export_process.output.download_uri)\n",
    "    with open(\"od_model_tensorflow.zip\", \"wb\") as file:\n",
    "        file.write(model_export_file.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
