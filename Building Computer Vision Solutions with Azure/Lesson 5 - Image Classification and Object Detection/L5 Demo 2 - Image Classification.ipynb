{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please install the required Python modules/SDKs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find conda environment: ai-azure-c1\r\n",
      "You can list all discoverable environments with `conda info --envs`.\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "! activate ai-azure-c1\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"/opt/conda/envs/ai-azure-c1/lib/python3.8/site-packages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure Custom Vision - Image Classification Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing utility functions and Python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os, time, uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.cognitiveservices.vision.customvision.training import CustomVisionTrainingClient\n",
    "from azure.cognitiveservices.vision.customvision.prediction import CustomVisionPredictionClient\n",
    "from azure.cognitiveservices.vision.customvision.training.models import ImageFileCreateBatch, ImageFileCreateEntry, Region\n",
    "from msrest.authentication import ApiKeyCredentials\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources:\n",
    "- Azure Custom Vision Endpoint\n",
    "- Training Reource ID and Key\n",
    "- Prediction Resource ID and Key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make sure you have the correct Training and Prediction Endpoints, Keys and Resource IDs separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_ENDPOINT = \"https://nayanacustomvision.cognitiveservices.azure.com/\"\n",
    "training_key = \"ce08598caf404621b37136119dccd921\"\n",
    "training_resource_id = \"/subscriptions/bb272072-9c6d-4e28-b814-947814c3e6ef/resourceGroups/nayana-ai-msft-azure/providers/Microsoft.CognitiveServices/accounts/nayanacustomvision\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREDICTION_ENDPOINT = \"https://nayanacustomvision-prediction.cognitiveservices.azure.com/\"\n",
    "prediction_key = \"6b7c1fe2bea0431a8a3b4259749591e6\"\n",
    "prediction_resource_id = \"/subscriptions/bb272072-9c6d-4e28-b814-947814c3e6ef/resourceGroups/nayana-ai-msft-azure/providers/Microsoft.CognitiveServices/accounts/nayanacustomvision-Prediction\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate and authenticate the training client with endpoint and key "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_credentials = ApiKeyCredentials(in_headers={\"Training-key\": training_key})\n",
    "trainer = CustomVisionTrainingClient(TRAINING_ENDPOINT, training_credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.4-preview'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.api_version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Training Project First"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training project created. Proceed to the next cell.\n"
     ]
    }
   ],
   "source": [
    "# Create a new project\n",
    "print (\"Training project created. Proceed to the next cell.\")\n",
    "project_name = uuid.uuid4()\n",
    "project = trainer.create_project(project_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Project Details as collective information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '5fcb2b44-ec8b-4b30-b430-b835afe8ec74',\n",
       " 'name': 'e859911c-a2d8-473b-a27a-7497595f24ad',\n",
       " 'description': '',\n",
       " 'settings': {'domain_id': 'ee85a74c-405e-4adc-bb47-ffa8ca0c9f31',\n",
       "  'classification_type': 'Multilabel',\n",
       "  'target_export_platforms': [],\n",
       "  'use_negative_set': True,\n",
       "  'image_processing_settings': {'augmentation_methods': {'rotation': True,\n",
       "    'scaling': True,\n",
       "    'translation': True,\n",
       "    'horizontal flip': True,\n",
       "    'equalize': True,\n",
       "    'solarize': True,\n",
       "    'padtosquare': True}}},\n",
       " 'created': '2022-06-15T18:21:31.643Z',\n",
       " 'last_modified': '2022-06-15T18:21:31.643Z',\n",
       " 'dr_mode_enabled': False,\n",
       " 'status': 'Succeeded'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project.as_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Tags based on training requirements\n",
    "- We have 3 tags in the training process \n",
    "  - nature\n",
    "  - architecture\n",
    "  - interior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nature_tag = trainer.create_tag(project.id, \"Nature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "architecture_tag = trainer.create_tag(project.id, \"Architecture\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "interior_tag = trainer.create_tag(project.id, \"Interior\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Traning Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enter local file system location of the traning images \n",
    "- All training images are saved in the file system within this workspace environment. \n",
    "- You can click on the \"Jupyter\" icon on the top left of this workspace to view these image folders:\n",
    "    - You will find all nature images in the `nature-images` folder\n",
    "    - You will find all architecture images in the `architecture-images` folder\n",
    "    - You will find all the interior images in the `interior-images` folder\n",
    "    - There are also three test images for you to perform predictions later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nayanex/Desktop/Udacity/AI-Engineer-using-Microsoft-Azure-Nanodegree-Program/Building Computer Vision Solutions with Azure/Lesson 5 - Image Classification and Object Detection\r\n"
     ]
    }
   ],
   "source": [
    "# Get current working directory\n",
    "# The output will give you the \"local_image_path\" used in the cell below\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_image_path = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some code is taken from Azure SDK Sample and added my own code here\n",
    "def upload_images_for_training(local_project_id, local_img_folder_name, image_tag_id):\n",
    "    image_list = []\n",
    "    files = os.listdir(os.path.join (local_image_path, local_img_folder_name))\n",
    "    for file in files:\n",
    "        full_path = os.path.join(local_image_path, local_img_folder_name, file)\n",
    "        if os.path.isfile(full_path) and full_path.endswith('.jpeg'):\n",
    "            with open(os.path.join (local_image_path, local_img_folder_name, file), \"rb\") as image_contents:\n",
    "                image_list.append(ImageFileCreateEntry(name=file, contents=image_contents.read(), tag_ids=[image_tag_id]))\n",
    "                \n",
    "    upload_result = trainer.create_images_from_files(local_project_id, ImageFileCreateBatch(images=image_list))\n",
    "    if not upload_result.is_batch_successful:\n",
    "        print(\"Image batch upload failed.\")\n",
    "        for image in upload_result.images:\n",
    "            print(\"Image status: \", image.status)\n",
    "        exit(-1)\n",
    "    return upload_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "nature_upload_result = upload_images_for_training(project.id, 'nature-images', nature_tag.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nature_upload_result.is_batch_successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "architecture_upload_result = upload_images_for_training(project.id, 'architecture-images', architecture_tag.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "architecture_upload_result.is_batch_successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "interior_upload_result = upload_images_for_training(project.id, 'interior-images', interior_tag.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interior_upload_result.is_batch_successful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the Image Classification Training\n",
    "- We will keep checking the training progress every 10 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Training\n",
      "Waiting 10 seconds...\n",
      "Training status: Completed\n",
      "Waiting 10 seconds...\n"
     ]
    }
   ],
   "source": [
    "iteration = trainer.train_project(project.id)\n",
    "while (iteration.status != \"Completed\"):\n",
    "    iteration = trainer.get_iteration(project.id, iteration.id)\n",
    "    print (\"Training status: \" + iteration.status)\n",
    "    print (\"Waiting 10 seconds...\")\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After training is complete, let's look at the Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'd8e23eaa-4fc1-4ba8-85cd-5b90a8f4e980',\n",
       " 'name': 'Iteration 1',\n",
       " 'status': 'Completed',\n",
       " 'created': '2022-06-15T18:21:31.646Z',\n",
       " 'last_modified': '2022-06-15T18:29:24.820Z',\n",
       " 'trained_at': '2022-06-15T18:29:24.774Z',\n",
       " 'project_id': '5fcb2b44-ec8b-4b30-b430-b835afe8ec74',\n",
       " 'exportable': False,\n",
       " 'domain_id': 'ee85a74c-405e-4adc-bb47-ffa8ca0c9f31',\n",
       " 'classification_type': 'Multilabel',\n",
       " 'training_type': 'Regular',\n",
       " 'reserved_budget_in_hours': 0,\n",
       " 'training_time_in_minutes': 4}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iteration.as_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'additional_properties': {}, 'id': 'd8e23eaa-4fc1-4ba8-85cd-5b90a8f4e980', 'name': 'Iteration 1', 'status': 'Completed', 'created': datetime.datetime(2022, 6, 15, 18, 21, 31, 646000, tzinfo=<isodate.tzinfo.Utc object at 0x7fc06b47c940>), 'last_modified': datetime.datetime(2022, 6, 15, 18, 29, 24, 820000, tzinfo=<isodate.tzinfo.Utc object at 0x7fc06b47c940>), 'trained_at': datetime.datetime(2022, 6, 15, 18, 29, 24, 774000, tzinfo=<isodate.tzinfo.Utc object at 0x7fc06b47c940>), 'project_id': '5fcb2b44-ec8b-4b30-b430-b835afe8ec74', 'exportable': False, 'exportable_to': None, 'domain_id': 'ee85a74c-405e-4adc-bb47-ffa8ca0c9f31', 'classification_type': 'Multilabel', 'training_type': 'Regular', 'reserved_budget_in_hours': 0, 'training_time_in_minutes': 4, 'publish_name': None, 'original_publish_resource_id': None, 'custom_base_model_info': None, 'training_error_details': None}\n"
     ]
    }
   ],
   "source": [
    "iteration_list = trainer.get_iterations(project.id)\n",
    "for iteration_item in iteration_list:\n",
    "    print(iteration_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_perf = trainer.get_iteration_performance(project.id, iteration_list[0].id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'per_tag_performance': [{'id': 'de75ded1-4837-418f-b9eb-8d23d5b82d0f',\n",
       "   'name': 'Architecture',\n",
       "   'precision': 1.0,\n",
       "   'precision_std_deviation': 0.0,\n",
       "   'recall': 1.0,\n",
       "   'recall_std_deviation': 0.0,\n",
       "   'average_precision': 1.0},\n",
       "  {'id': 'fde7f5d6-f3d1-4d9a-8612-bcd36bf69ea0',\n",
       "   'name': 'Interior',\n",
       "   'precision': 1.0,\n",
       "   'precision_std_deviation': 0.0,\n",
       "   'recall': 1.0,\n",
       "   'recall_std_deviation': 0.0,\n",
       "   'average_precision': 1.0},\n",
       "  {'id': '9a765e97-345c-4d36-8bc0-5d4bb8763abc',\n",
       "   'name': 'Nature',\n",
       "   'precision': 1.0,\n",
       "   'precision_std_deviation': 0.0,\n",
       "   'recall': 1.0,\n",
       "   'recall_std_deviation': 0.0,\n",
       "   'average_precision': 1.0}],\n",
       " 'precision': 1.0,\n",
       " 'precision_std_deviation': 0.0,\n",
       " 'recall': 1.0,\n",
       " 'recall_std_deviation': 0.0,\n",
       " 'average_precision': 1.0}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_perf.as_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publishing the Model to the Project Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the Iteration Name, this will be used when Model training is completed\n",
    "# Please choose a name favorable to you.\n",
    "publish_iteration_name = \"udacity-3-class-classification-demo-custom\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# The iteration is now trained. Publish it to the project endpoint\n",
    "trainer.publish_iteration(project.id, iteration.id, publish_iteration_name, prediction_resource_id)\n",
    "print (\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate and authenticate the prediction client with endpoint and key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_credentials = ApiKeyCredentials(in_headers={\"Prediction-key\": prediction_key})\n",
    "predictor = CustomVisionPredictionClient(PREDICTION_ENDPOINT, prediction_credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.1'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.api_version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing Prediction\n",
    "- Using the predictor object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_prediction(image_file_name):\n",
    "    with open(os.path.join (local_image_path,  image_file_name), \"rb\") as image_contents:\n",
    "        results = predictor.classify_image(project.id, publish_iteration_name, image_contents.read())\n",
    "        # Display the results.\n",
    "        for prediction in results.predictions:\n",
    "            print(\"\\t\" + prediction.tag_name +\n",
    "                  \": {0:.2f}%\".format(prediction.probability * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The test images are stored in the local file system of this workspace\n",
    "* You will perform prediction twice below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L5 Demo 1 - Predict API.ipynb          \u001b[34marchitecture-images\u001b[m\u001b[m\r\n",
      "L5 Demo 2 - Image Classification.ipynb \u001b[34minterior-images\u001b[m\u001b[m\r\n",
      "L5 Image Classification Exercise.ipynb \u001b[34mnature-images\u001b[m\u001b[m\r\n",
      "README.md                              \u001b[34mtest-architecture\u001b[m\u001b[m\r\n",
      "\u001b[34manimals\u001b[m\u001b[m                                \u001b[34mtest-nature\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "# To list the folders/files in your current working directory\n",
    "# The name of any image file can be used as \"file_name\" in the cell below\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'test-architecture-01.jpeg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'test-architecture-01.jpeg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [36]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Pick one test image file name from the output of the previous cell\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Use the same image file name for this cell and the next one\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mperform_prediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [31]\u001b[0m, in \u001b[0;36mperform_prediction\u001b[0;34m(image_file_name)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mperform_prediction\u001b[39m(image_file_name):\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocal_image_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mimage_file_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m image_contents:\n\u001b[1;32m      3\u001b[0m         results \u001b[38;5;241m=\u001b[39m predictor\u001b[38;5;241m.\u001b[39mclassify_image(project\u001b[38;5;241m.\u001b[39mid, publish_iteration_name, image_contents\u001b[38;5;241m.\u001b[39mread())\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;66;03m# Display the results.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'test-architecture-01.jpeg'"
     ]
    }
   ],
   "source": [
    "# Pick one test image file name from the output of the previous cell\n",
    "# Use the same image file name for this cell and the next one\n",
    "perform_prediction(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the image\n",
    "with open(os.path.join (local_image_path, file_name), 'rb') as img_code:\n",
    "    img_view_ready = Image.open(img_code)\n",
    "    plt.figure()\n",
    "    plt.imshow(img_view_ready)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name_2 = 'test-nature-02.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform prediction again using another image\n",
    "perform_prediction(file_name_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the second image\n",
    "with open(os.path.join (local_image_path, file_name_2), 'rb') as img_code:\n",
    "    img_view_ready = Image.open(img_code)\n",
    "    plt.figure()\n",
    "    plt.imshow(img_view_ready)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a507296ef207c85dcd85861be0f31321bce242707f259e326f95ccfad26e3249"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
